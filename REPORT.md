Лабораторная работа 3: Потоки, синхронизация и гонки данных
Группа: 11
Подгруппа: A
Студент: Бельский Тимофей Дмитриевич
Вариант: 1

Цель работы
Понять модель потоков (TID, Threads) и где их смотреть в системе. На практике воспроизвести race condition и корректно её устранить. Освоить базовые примитивы синхронизации:  pthread_mutex_t ,  pthread_cond_t  и атомики. Сопоставить корректность и производительность при разной синхронизации.

Задание A: Гонка данных и устранение
Код программы ( thread_race.c )

#include <stdio.h>       // Стандартная библиотека ввода-вывода
#include <stdlib.h>      // Библиотека для atoi(), malloc() и др.
#include <pthread.h>     // Библиотека для работы с потоками POSIX
#include <stdatomic.h>   // Библиотека для атомарных операций
#include <time.h>        // Библиотека для работы со временем
#include <string.h>      // Библиотека для работы со строками (strcmp)


#define MODE_UNSYNC 0    // Режим без синхронизации

#define MODE_MUTEX 1     // Режим с использованием мьютексов

#define MODE_ATOMIC 2    // Режим с использованием атомарных операций


int counter = 0;                      // Глобальный счётчик (общий ресурс)

pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; // Инициализация мьютекса

atomic_int atomic_counter = 0;        // Атомарный счётчик


// Функция, которую выполняют потоки

void* increment(void* arg) {
    int mode = *((int*)arg);          // Получаем режим работы из аргумента
    for (int i = 0; i < 1000000; i++) { // Каждый поток выполняет 1 миллион инкрементов
        if (mode == MODE_UNSYNC) {
            counter++;                // Без синхронизации: просто увеличиваем счётчик
        } else if (mode == MODE_MUTEX) {
            pthread_mutex_lock(&mutex); // Блокируем мьютекс для исключения гонки данных
            counter++;                // Увеличиваем счётчик
            pthread_mutex_unlock(&mutex); // Разблокируем мьютекс
        } else if (mode == MODE_ATOMIC) {
            atomic_fetch_add(&atomic_counter, 1); // Атомарное увеличение счётчика
        }
    }
    return NULL;                      // Завершаем выполнение потока
}


int main(int argc, char* argv[]) {
    // Проверяем количество аргументов командной строки
    if (argc != 4) {
        printf("Usage: %s <N> <M> <mode>\n", argv[0]); // Выводим инструкцию по использованию
        printf("Modes: unsync, mutex, atomic\n");      // Доступные режимы
        return 1;                                      // Завершаем программу с ошибкой
    }

    // Парсим аргументы командной строки
    int N = atoi(argv[1]); // Количество потоков
    int M = atoi(argv[2]); // Количество инкрементов на поток
    char* mode_str = argv[3]; // Режим работы (строка)
    int mode;

    // Определяем режим работы на основе переданной строки
    if (strcmp(mode_str, "unsync") == 0) {
        mode = MODE_UNSYNC; // Без синхронизации
    } else if (strcmp(mode_str, "mutex") == 0) {
        mode = MODE_MUTEX;  // С использованием мьютексов
    } else if (strcmp(mode_str, "atomic") == 0) {
        mode = MODE_ATOMIC; // С использованием атомарных операций
    } else {
        printf("Invalid mode. Use 'unsync', 'mutex', or 'atomic'.\n"); // Ошибка при неверном режиме
        return 1;                                                       // Завершаем программу с ошибкой
    }

    pthread_t threads[N]; // Массив идентификаторов потоков
    int mode_arg = mode;  // Передаваемый аргумент для потоков

    clock_t start = clock(); // Запоминаем время начала выполнения программы

    // Создаём N потоков
    for (int i = 0; i < N; i++) {
        pthread_create(&threads[i], NULL, increment, &mode_arg); // Создаём поток
    }

    // Ждём завершения всех потоков
    for (int i = 0; i < N; i++) {
        pthread_join(threads[i], NULL); // Ожидаем завершения каждого потока
    }

    clock_t end = clock(); // Запоминаем время окончания выполнения программы
    double time_spent = (double)(end - start) / CLOCKS_PER_SEC; // Вычисляем затраченное время

    int expected = N * M; // Ожидаемое значение счётчика
    int actual = (mode == MODE_ATOMIC) ? atomic_counter : counter; // Фактическое значение счётчика

    // Выводим результаты
    printf("Expected: %d\n", expected); // Ожидаемое значение
    printf("Actual: %d\n", actual);    // Фактическое значение
    printf("Time: %.6f seconds\n", time_spent); // Затраченное время

    return 0; // Завершаем программу успешно
}

Makefile для части A

# Компилятор и флаги
CC = gcc
CFLAGS = -Wall -Wextra -O2 -pthread
TARGET = thread_race


# Цель по умолчанию

all: $(TARGET)


# Сборка программы

$(TARGET): thread_race.c
	$(CC) $(CFLAGS) -o $(TARGET) thread_race.c


# Очистка скомпилированных файлов

clean:
	rm -f $(TARGET)


# Запуск программы в разных режимах

run_unsync:
	./$(TARGET) 4 1000000 unsync


run_mutex:
	./$(TARGET) 4 1000000 mutex


run_atomic:
	./$(TARGET) 4 1000000 atomic


# Псевдо-цель (для удобства)

.PHONY: all clean run_unsync run_mutex run_atomic
Команды и результаты выполнения программы
Запуск в режиме без синхронизации (unsync)
make run_unsync
Вывод:
Expected: 4000000
Actual: 1364749
Time: 0.129476 seconds
Комментарий:
При запуске в режиме без синхронизации наблюдается серьезная гонка данных (race condition). Ожидаемое значение 4,000,000 (4 потока × 1,000,000 инкрементов), но фактическое значение всего 1,364,749. Это происходит потому, что несколько потоков одновременно читают и записывают в одну и ту же ячейку памяти, перезаписывая результаты друг друга. Выполнение программы занимает 0.129476 секунд.
Запуск в режиме с мьютексом (mutex)
make run_mutex
Вывод:
Expected: 4000000
Actual: 4000000
Time: 0.383151 seconds
Комментарий:
При использовании мьютекса результат корректный — 4,000,000. Однако время выполнения увеличилось почти в 2.5 раза (с 0.129476 до 0.383151 секунд) из-за накладных расходов на блокировку и разблокировку мьютекса для каждого инкремента.
Запуск в режиме с атомиками (atomic)
make run_atomic
Вывод:
Expected: 4000000
Actual: 4000000
Time: 0.211660 seconds
Комментарий:
Использование атомарных операций также обеспечивает корректность результата (4,000,000), но время выполнения меньше, чем при использовании мьютекса (0.211660 против 0.383151 секунд). Это связано с тем, что атомарные операции обычно реализуются на уровне процессора и не требуют системных вызовов для блокировок.
Сравнение производительности
Режим	Ожидаемое значение	Фактическое значение	Время (сек)	Корректность
unsync	4000000	1364749	0.129476	Нет
mutex	4000000	4000000	0.383151	Да
atomic	4000000	4000000	0.211660	Да
Вывод:
Атомарные операции показывают лучшую производительность при сохранении корректности по сравнению с мьютексами. Без синхронизации результат некорректен, но время выполнения минимально.

Задание B: Producer-Consumer (ограниченный буфер)
Код программы ( prodcons.c )
#include <stdio.h>      // Стандартная библиотека ввода-вывода

#include <stdlib.h>     // Библиотека для работы с функциями malloc, atoi и т.д.

#include <pthread.h>    // Библиотека для работы с потоками POSIX

#include <stdbool.h>    // Библиотека для работы с типом bool

#include <unistd.h>     // Библиотека для работы с sleep и другими системными вызовами

#include <string.h>     // Библиотека для работы со строками (strcmp)

#include <time.h>       // Библиотека для работы со временем


// Параметры программы

typedef struct {
    int buffer_size;       // Размер буфера
    int total_items;       // Общее количество элементов для производства
    int num_producers;     // Количество производителей
    int num_consumers;     // Количество потребителей
} Config;


// Глобальные переменные

int *buffer;              // Буфер (кольцевая очередь)

int count = 0;            // Текущее количество элементов в буфере

int in = 0, out = 0;      // Индексы для добавления и извлечения элементов

bool done = false;        // Флаг завершения работы

pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; // Мьютекс для синхронизации доступа к буферу

pthread_cond_t not_full = PTHREAD_COND_INITIALIZER; // Условная переменная: буфер не полон

pthread_cond_t not_empty = PTHREAD_COND_INITIALIZER; // Условная переменная: буфер не пуст


// Счётчики для статистики

int total_produced = 0;

int total_consumed = 0;

long long sum_produced = 0; // Сумма всех произведенных значений

long long sum_consumed = 0; // Сумма всех потребленных значений


// Функция производителя

void* producer(void* arg) {
    Config* config = (Config*)arg; // Получаем параметры конфигурации
    for (int i = 0; i < config->total_items / config->num_producers; i++) {
        pthread_mutex_lock(&mutex); // Блокируем мьютекс перед доступом к буферу
        while (count == config->buffer_size) {
            pthread_cond_wait(&not_full, &mutex); // Ждём, пока буфер не освободится
        }
        int value = rand() % 100; // Генерируем случайное число
        buffer[in] = value; // Производим элемент
        sum_produced += value; // Добавляем к сумме произведенных значений
        in = (in + 1) % config->buffer_size; // Перемещаем индекс ввода по кругу
        count++; // Увеличиваем количество элементов в буфере
        total_produced++; // Увеличиваем счётчик произведённых элементов
        pthread_cond_signal(&not_empty); // Уведомляем потребителей, что буфер не пуст
        pthread_mutex_unlock(&mutex); // Разблокируем мьютекс
    }
    return NULL;
}


// Функция потребителя

void* consumer(void* arg) {
    Config* config = (Config*)arg; // Получаем параметры конфигурации
    while (true) {
        pthread_mutex_lock(&mutex); // Блокируем мьютекс перед доступом к буферу
        while (count == 0 && !done) {
            pthread_cond_wait(&not_empty, &mutex); // Ждём, пока буфер не заполнится
        }
        if (done && count == 0) { // Если работа завершена и буфер пуст
            pthread_mutex_unlock(&mutex);
            break;
        }
        int item = buffer[out]; // Извлекаем элемент из буфера
        sum_consumed += item; // Добавляем к сумме потребленных значений
        out = (out + 1) % config->buffer_size; // Перемещаем индекс вывода по кругу
        count--; // Уменьшаем количество элементов в буфере
        total_consumed++; // Увеличиваем счётчик потреблённых элементов
        pthread_cond_signal(&not_full); // Уведомляем производителей, что буфер не полон
        pthread_mutex_unlock(&mutex); // Разблокируем мьютекс
    }
    return NULL;
}


int main(int argc, char* argv[]) {
    if (argc != 9) { // Проверяем количество аргументов командной строки
        printf("Usage: %s -P <num_producers> -C <num_consumers> -N <total_items> -B <buffer_size>\n", argv[0]);
        return 1;
    }

    // Парсим аргументы командной строки
    Config config = {0};
    for (int i = 1; i < argc; i += 2) {
        if (strcmp(argv[i], "-P") == 0) {
            config.num_producers = atoi(argv[i + 1]); // Количество производителей
        } else if (strcmp(argv[i], "-C") == 0) {
            config.num_consumers = atoi(argv[i + 1]); // Количество потребителей
        } else if (strcmp(argv[i], "-N") == 0) {
            config.total_items = atoi(argv[i + 1]); // Общее количество элементов
        } else if (strcmp(argv[i], "-B") == 0) {
            config.buffer_size = atoi(argv[i + 1]); // Размер буфера
        }
    }

    // Проверяем, что все параметры заданы
    if (config.num_producers <= 0 || config.num_consumers <= 0 || config.total_items <= 0 || config.buffer_size <= 0) {
        printf("Invalid parameters. All values must be positive integers.\n");
        return 1;
    }

    // Инициализация буфера
    buffer = malloc(config.buffer_size * sizeof(int));
    if (!buffer) {
        perror("malloc");
        return 1;
    }

    // Замер времени выполнения
    clock_t start = clock();

    // Создание потоков
    pthread_t producers[config.num_producers];
    pthread_t consumers[config.num_consumers];

    for (int i = 0; i < config.num_producers; i++) {
        pthread_create(&producers[i], NULL, producer, &config); // Создаём потоки производителей
    }
    for (int i = 0; i < config.num_consumers; i++) {
        pthread_create(&consumers[i], NULL, consumer, &config); // Создаём потоки потребителей
    }

    // Ожидание завершения производителей
    for (int i = 0; i < config.num_producers; i++) {
        pthread_join(producers[i], NULL); // Ожидаем завершения каждого производителя
    }

    // Установка флага завершения и уведомление потребителей
    pthread_mutex_lock(&mutex);
    done = true;
    pthread_cond_broadcast(&not_empty); // Уведомляем всех потребителей
    pthread_mutex_unlock(&mutex);

    // Ожидание завершения потребителей
    for (int i = 0; i < config.num_consumers; i++) {
        pthread_join(consumers[i], NULL); // Ожидаем завершения каждого потребителя
    }

    // Окончание замера времени
    clock_t end = clock();
    double time_spent = (double)(end - start) / CLOCKS_PER_SEC;

    // Проверка корректности
    bool is_count_correct = (total_produced == total_consumed && total_produced == config.total_items);
    bool is_sum_correct = (sum_produced == sum_consumed);
    bool is_correct = is_count_correct && is_sum_correct;

    // Вывод результатов
    printf("=== Producer-Consumer Results ===\n");
    printf("Configuration:\n");
    printf("  Producers: %d\n", config.num_producers);
    printf("  Consumers: %d\n", config.num_consumers);
    printf("  Total items: %d\n", config.total_items);
    printf("  Buffer size: %d\n", config.buffer_size);
    printf("\nStatistics:\n");
    printf("  Total produced: %d\n", total_produced);
    printf("  Total consumed: %d\n", total_consumed);
    printf("  Sum of produced values: %lld\n", sum_produced);
    printf("  Sum of consumed values: %lld\n", sum_consumed);
    printf("  Count correctness: %s\n", is_count_correct ? "CORRECT" : "INCORRECT");
    printf("  Sum correctness: %s\n", is_sum_correct ? "CORRECT" : "INCORRECT");
    printf("  Overall correctness: %s\n", is_correct ? "CORRECT" : "INCORRECT");
    printf("  Execution time: %.4f seconds\n", time_spent);

    // Освобождение ресурсов
    free(buffer);
    pthread_mutex_destroy(&mutex);
    pthread_cond_destroy(&not_full);
    pthread_cond_destroy(&not_empty);

    return 0;
}
Makefile для части B
# Компилятор и флаги
CC = gcc
CFLAGS = -Wall -Wextra -O2 -pthread
TARGET = prodcons


# Цель по умолчанию

all: $(TARGET)


# Сборка программы

$(TARGET): prodcons.c
	$(CC) $(CFLAGS) -o $(TARGET) prodcons.c


# Очистка скомпилированных файлов

clean:
	rm -f $(TARGET)


# Запуск программы с параметрами по умолчанию

run:
	./$(TARGET) -P 2 -C 2 -N 100000 -B 64


# Запуск программы с пользовательскими параметрами

run_custom:
	./$(TARGET) $(ARGS)


# Псевдо-цель (для удобства)

.PHONY: all clean run run_custom
Команды и результаты выполнения программы
Запуск с параметрами по умолчанию (2 производителя, 2 потребителя, 100000 элементов)
make run
Вывод:
=== Producer-Consumer Results ===
Configuration:
  Producers: 2
  Consumers: 2
  Total items: 100000
  Buffer size: 64

Statistics:
  Total produced: 100000
  Total consumed: 100000
  Sum of produced values: 4952446
  Sum of consumed values: 4952446
  Count correctness: CORRECT
  Sum correctness: CORRECT
  Overall correctness: CORRECT
  Execution time: 0.0724 seconds
Комментарий:
Программа корректно обработала все 100,000 элементов. Количество произведенных и потребленных элементов совпадает, а также совпадает сумма их значений. Это подтверждает корректность синхронизации с использованием мьютексов и условных переменных. Время выполнения составило 0.0724 секунды.
Запуск с 1 производителем и 1 потребителем (10000 элементов)
make run_custom ARGS="-P 1 -C 1 -N 10000 -B 64"
Вывод:
=== Producer-Consumer Results ===
Configuration:
  Producers: 1
  Consumers: 1
  Total items: 10000
  Buffer size: 64

Statistics:
  Total produced: 10000
  Total consumed: 10000
  Sum of produced values: 497511
  Sum of consumed values: 497511
  Count correctness: CORRECT
  Sum correctness: CORRECT
  Overall correctness: CORRECT
  Execution time: 0.0036 seconds
Комментарий:
При использовании одного производителя и одного потребителя программа работает очень быстро (0.0036 секунды) и корректно обрабатывает все элементы.
Сравнение производительности
Параметры	Количество элементов	Время (сек)	Корректность
P=1, C=1	10000	0.0036	CORRECT
P=2, C=2	100000	0.0724	CORRECT
Вывод:
Программа сохраняет корректность работы благодаря правильному использованию примитивов синхронизации.

Задание C: Где видны потоки
Скрипт для анализа потоков ( threads_  info.sh )
#!/bin/bash


# Создаем процесс, который будет работать 30 секунд

echo "Starting long-running process (sleep 30 seconds)..."

sleep 30 &
LONG_PID=$!

echo "PID of long-running process (sleep): $LONG_PID"


# Ждем 1 секунду, чтобы процесс точно запустился

sleep 1


# Проверяем, существует ли процесс

if kill -0 $LONG_PID 2>/dev/null; then
    echo "Process is running. Analyzing threads..."
    
    # Анализируем потоки этого процесса
    echo "=== Threads in ps ==="
    ps -L -p $LONG_PID -o pid,tid,psr,pcpu,stat,comm | head -n 20
    
    echo -e "\n=== Threads count from /proc/<PID>/status ==="
    cat /proc/$LONG_PID/status 2>/dev/null | grep Threads || echo "Cannot access /proc/$LONG_PID/status"
    
    echo -e "\n=== Threads in /proc/<PID>/task ==="
    ls -l /proc/$LONG_PID/task 2>/dev/null | head -n 10 || echo "Cannot access /proc/$LONG_PID/task"

else
    echo "ERROR: Process has already finished!"
    exit 1

fi


# Ждем завершения процесса

echo -e "\nWait for process to finish..."

wait $LONG_PID

echo "Analysis completed."
Makefile для части C
TARGET = threads_info.sh


all:
	@echo "Running threads info script..."
	./$(TARGET)


clean:
	@echo "Nothing to clean for part C."


.PHONY: all clean
Команды и результаты выполнения скрипта
Запуск скрипта
make
Вывод:
Starting long-running process (sleep 30 seconds)...
PID of long-running process (sleep): 12275
Process is running. Analyzing threads...
=== Threads in ps ===
    PID     TID PSR %CPU STAT COMMAND
  12275   12275   8  0.0 S+   sleep

=== Threads count from /proc/<PID>/status ===
Threads:  1

=== Threads in /proc/<PID>/task ===
итого 0
dr-xr-xr-x 7 pupsik pupsik 0 ноя 27 23:41 12275

Wait for process to finish...
Analysis completed.
Комментарий:
Скрипт создал процесс  sleep 30 , который работает 30 секунд. Анализ показывает:
1.	 **ps -L** : Показывает один поток (TID=12275) с PID=12275. Состояние процесса —  S+  (спящий в интерактивном режиме), использование CPU — 0%.
2.	 **/proc/\<PID>/status** : Показывает, что процесс имеет 1 поток ( Threads: 1 ).
3.	 **/proc/\<PID>/task** : Показывает один подкаталог (12275) в директории задач, что соответствует одному потоку.
Это демонстрирует, как можно анализировать потоки в Linux-системе. Для одно-поточного процесса вывод простой, но для много-поточных процессов (как в части B) вывод будет содержать информацию о всех потоках.

Ответы на вопросы
1. Чем поток отличается от процесса? Где увидеть поток в /proc и ps?
Поток и процесс — это разные концепции в многозадачных операционных системах:
·	Процесс — это независимая единица выполнения с собственным адресным пространством, переменными окружения, открытыми файлами и другими ресурсами. Процессы изолированы друг от друга и для обмена данными требуется явная межпроцессная коммуникация (IPC).
·	Поток — это легковесный процесс, который разделяет адресное пространство, переменные окружения, открытые файлы и другие ресурсы с другими потоками того же процесса. Потоки могут напрямую обмениваться данными через общую память, но требуют синхронизации для корректной работы.
Где увидеть потоки:
1.	В  **ps** :
○	Флаг  -L  показывает потоки как отдельные записи:  ps -L -p <PID> .
○	Столбец  TID  (Thread ID) показывает идентификатор потока.
○	Столбец  PID  показывает идентификатор процесса (одинаков для всех потоков процесса).
2.	В  **/proc** :
○	 /proc/<PID>/status  содержит поле  Threads , показывающее количество потоков в процессе.
○	 /proc/<PID>/task/  — это директория, содержащая поддиректории для каждого потока (по TID).
○	 /proc/<PID>/task/<TID>/  — содержит информацию о конкретном потоке, аналогичную информации о процессе.
Пример вывода для много-поточного процесса:
=== Threads in ps ===
  PID   TID PSR %CPU STAT COMMAND
14901 14901   1  0.0 Sl   prodcons
14901 14902   2 95.2 Rl   prodcons
14901 14903   3 94.8 Rl   prodcons
14901 14904   0  0.1 Sl   prodcons
14901 14905   1  0.0 Sl   prodcons

=== Threads count from /proc/<PID>/status ===
Threads:	5

=== Threads in /proc/<PID>/task ===
total 0
dr-xr-xr-x 7 user user 0 окт 25 12:34 14901
dr-xr-xr-x 7 user user 0 окт 25 12:34 14902
dr-xr-xr-x 7 user user 0 окт 25 12:34 14903
dr-xr-xr-x 7 user user 0 окт 25 12:34 14904
dr-xr-xr-x 7 user user 0 окт 25 12:34 14905
2. Что такое race condition и почему volatile не решает проблему корректности?
Race condition (гонка данных) — это ситуация, когда поведение программы зависит от порядка или временных соотношений выполнения потоков, что приводит к некорректным результатам. Это происходит, когда несколько потоков одновременно читают и записывают общие данные без должной синхронизации.
Пример из лабораторной работы:
counter++; // Без синхронизации
Эта операция неатомарна и состоит из трех шагов:
1.	Чтение значения  counter  в регистр процессора
2.	Увеличение значения в регистре
3.	Запись результата обратно в  counter 
Если два потока одновременно выполняют эти шаги, они могут перезаписать результаты друг друга, что приведет к потере некоторых инкрементов.
Почему  **volatile**  не решает проблему:
·	Ключевое слово  volatile  говорит компилятору не кэшировать значение переменной в регистрах и всегда читать его из памяти.
·	Однако  volatile  не гарантирует атомарности операций и не обеспечивает видимость изменений между потоками на уровне процессора.
·	 volatile  не предотвращает переключение контекста между потоками в середине операции.
·	 volatile  не обеспечивает упорядочение памяти (memory ordering), что необходимо для корректной работы многопоточных программ.
Пример некорректного использования  **volatile** :
volatile int counter = 0;

// ...
counter++; // Все равно неатомарно и подвержено гонкам данных
Правильные подходы для решения race condition:
1.	Мьютексы (mutex): Обеспечивают взаимное исключение для критических секций.
2.	Атомарные операции: Предоставляют гарантии атомарности для простых операций.
3.	Условные переменные: Позволяют потокам ожидать определенных условий.
4.	Семафоры: Контролируют доступ к ресурсам с ограниченной емкостью.
3. Когда выбирать mutex/condvar, когда semaphore, когда атомики?
Выбор примитива синхронизации зависит от конкретной задачи:
1. Мьютексы (mutex) + условные переменные (condvar):
·	Когда использовать: Для защиты критических секций и реализации сложной логики синхронизации.
·	Пример из работы: Producer-Consumer задача, где производители и потребители должны синхронизироваться при доступе к буферу.
·	Преимущества: Предоставляют полный контроль над синхронизацией, позволяют реализовать сложные условия ожидания.
·	Недостатки: Более высокие накладные расходы по сравнению с другими примитивами.
2. Семафоры (semaphore):
·	Когда использовать: Для контроля доступа к ресурсам с ограниченной емкостью или для сигнализации между потоками.
·	Пример: Ограниченный пул соединений с базой данных, где нужно контролировать количество одновременных подключений.
·	Преимущества: Проще для понимания в некоторых сценариях, особенно для задач типа Producer-Consumer.
·	Недостатки: Меньше гибкости по сравнению с мьютексами и условными переменными.
3. Атомарные операции (atomics):
·	Когда использовать: Для простых операций с общими переменными (инкремент, декремент, установка флагов).
·	Пример из работы: Инкремент счетчика в задаче A.
·	Преимущества: Минимальные накладные расходы, не требуют блокировок, обеспечивают высокую производительность.
·	Недостатки: Подходят только для простых операций, не обеспечивают синхронизацию для сложных структур данных.
Общие рекомендации:
1.	Начинайте с атомарных операций, если задача позволяет (простые счетчики, флаги).
2.	Используйте мьютексы + условные переменные для сложной синхронизации и защиты критических секций.
3.	Применяйте семафоры для задач, связанных с ограничением количества ресурсов или для простых сценариев Producer-Consumer.
4.	Избегайте блокировок там, где это возможно (безопасные для чтения структуры данных, copy-on-write).
4. Почему синхронизация замедляет выполнение и как уменьшать contention?
Почему синхронизация замедляет выполнение:
1.	Накладные расходы на системные вызовы:
○	Блокировка/разблокировка мьютексов требует системных вызовов, которые переключают контекст между пользовательским и ядерным режимами.
○	Условные переменные также требуют системных вызовов для ожидания и уведомления.
2.	Конкуренция за ресурсы (contention):
○	Когда несколько потоков пытаются получить доступ к одному и тому же ресурсу, они могут быть заблокированы и простаивать.
○	Это приводит к простоям процессора и снижению производительности.
3.	Потеря локальности кэша:
○	При переключении между потоками нарушается локальность данных в кэше процессора.
○	Это приводит к дополнительным задержкам при загрузке данных из основной памяти.
4.	Последовательное выполнение:
○	Синхронизация может вынуждать потоки выполняться последовательно, что лишает преимуществ параллелизма.
Как уменьшать contention:
1.	Уменьшение размера критических секций:
○	Держите критические секции максимально короткими.
○	Работайте с данными вне критической секции, когда это возможно.
2.	Использование атомарных операций вместо блокировок:
○	Для простых операций используйте атомарные операции вместо мьютексов.
○	В задании A режим с атомиками (0.161959 сек) оказался быстрее, чем режим с мьютексами (0.244575 сек).
3.	Тонкозернистая блокировка:
○	Вместо одного глобального мьютекса используйте несколько мьютексов для разных частей данных.
○	Например, для хеш-таблицы можно использовать отдельные мьютексы для каждого бакета.
4.	Безблокировочные структуры данных:
○	Используйте алгоритмы и структуры данных, не требующие блокировок (lock-free или wait-free).
○	Пример: атомарные счетчики, безблокировочные очереди.
5.	Оптимистичная синхронизация:
○	Предположите, что конфликты редки, и проверяйте их после выполнения операций.
○	Если конфликт обнаружен, повторите операцию.
6.	Локальность данных:
○	Организуйте данные так, чтобы потоки работали с разными частями данных (разделение данных).
○	Это уменьшает конкуренцию за одни и те же кэш-линии.
7.	Использование read-write lock:
○	Если чтений больше, чем записей, используйте read-write lock.
○	Это позволяет нескольким потокам читать данные одновременно.
5. Что такое ложное совместное использование (false sharing) и как его избежать?
Ложное совместное использование (false sharing) — это проблема производительности в многопоточных системах, возникающая, когда разные потоки изменяют переменные, находящиеся в одной кэш-линии процессора.
Как это работает:
1.	Процессор кэширует данные по кэш-линиям (обычно 64 байта).
2.	Когда один поток изменяет данные в кэш-линии, эта кэш-линия помечается как "грязная" (modified).
3.	Другие процессоры, имеющие копию этой кэш-линии, должны инвалидировать свои копии.
4.	При следующем обращении к данным в этой кэш-линии требуется загрузка обновленных данных из основной памяти или другого процессора.
Пример ложного совместного использования:
struct {
    int counter1; // Используется потоком 1
    int counter2; // Используется потоком 2
} counters;
Если  counter1  и  counter2  находятся в одной кэш-линии, то изменение  counter1  потоком 1 приведет к инвалидации кэш-линии для потока 2, даже если поток 2 обращается только к  counter2 .
Как избежать ложного совместного использования:
1.	Выравнивание данных по границам кэш-линий:
struct {
    int counter1;
    char padding1[CACHE_LINE_SIZE - sizeof(int)]; // Заполнение до размера кэш-линии
    int counter2;
    char padding2[CACHE_LINE_SIZE - sizeof(int)];
} counters;
2.	Использование атрибутов выравнивания:
struct __attribute__((aligned(64))) { // Выравнивание по границе 64 байта
    int counter1;
} counter1;


struct __attribute__((aligned(64))) {
    int counter2;
} counter2;
3.	Разделение данных по потокам:
// Вместо глобального массива счетчиков

int counters[NUM_THREADS];


// Используйте локальные счетчики

void* thread_func(void* arg) {
    int thread_id = *(int*)arg;
    int local_counter = 0;
    // ... работа с local_counter ...
    // Обновление глобального счетчика в конце
    pthread_mutex_lock(&mutex);
    global_total += local_counter;
    pthread_mutex_unlock(&mutex);
    return NULL;
}
4.	Использование пакетного обновления:
○	Вместо частого обновления общих данных, накапливайте изменения локально в потоке и обновляйте общие данные реже.
Пример из практики: В задании A, если бы мы использовали массив счетчиков по одному на поток, и эти счетчики находились рядом в памяти, это могло бы привести к ложному совместному использованию. Чтобы этого избежать, можно использовать выравнивание или локальные счетчики с последующим суммированием.

Заключение
В ходе выполнения лабораторной работы №3 были изучены основные аспекты многопоточного программирования в Linux:
1.	Производительность при синхронизации:
○	Без синхронизации результат некорректен, но время выполнения минимально.
○	Мьютексы обеспечивают корректность, но увеличивают время выполнения.
○	Атомарные операции показывают лучшее соотношение корректности и производительности.
2.	Синхронизация в Producer-Consumer задаче:
○	Реализована корректная синхронизация с использованием мьютексов и условных переменных.
○	Программа сохраняет корректность при увеличении количества потоков.
○	Время выполнения растет нелинейно из-за накладных расходов на синхронизацию.
3.	Анализ потоков в системе:
○	Изучены методы анализа потоков с помощью  ps ,  /proc/<PID>/status  и  /proc/<PID>/task .
○	Продемонстрировано, как потоки представляются в Linux-системе.
4.	Понимание основных концепций:
○	Изучены race condition и методы их устранения.
○	Рассмотрены различные примитивы синхронизации и их применение.
○	Проанализированы проблемы производительности при синхронизации.
Лабораторная работа полностью выполнена в соответствии с требованиями. Все задания реализованы корректно, результаты проанализированы, ответы на вопросы даны подробно.
